{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:46.901001400Z",
     "start_time": "2025-04-21T11:18:37.093970700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rembg import remove as rembg_remove\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:46.917990400Z",
     "start_time": "2025-04-21T11:18:46.908221700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(\"../\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "LEAF_BASE = f\"{BASE_DIR}/dataset_bg_removed\"\n",
    "BG_DIR = f\"{BASE_DIR}/background_images\"\n",
    "OUT_BASE = f\"{BASE_DIR}/augmented-dataset\"\n",
    "\n",
    "print(\"LEAF_DIR:\", LEAF_BASE)\n",
    "print(\"BG_DIR:\", BG_DIR)\n",
    "print(\"OUT_DIR:\", OUT_BASE)\n",
    "\n",
    "TARGET_WIDTH = 600\n",
    "AUG_PER_LEAF = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:46.991259200Z",
     "start_time": "2025-04-21T11:18:46.917990400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(image, target_width):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = target_width / w\n",
    "    target_height = int(h * scale)\n",
    "    return cv2.resize(image, (target_width, target_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:46.995601900Z",
     "start_time": "2025-04-21T11:18:46.942500400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_affine(image):\n",
    "    rows, cols = image.shape[:2]\n",
    "    tx = random.uniform(-0.1, 0.1) * cols\n",
    "    ty = random.uniform(-0.1, 0.1) * rows\n",
    "    scale = random.uniform(0.8, 1.2)\n",
    "    angle = random.uniform(-15, 15)\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, scale)\n",
    "    M[0, 2] += tx\n",
    "    M[1, 2] += ty\n",
    "    return cv2.warpAffine(image, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:46.995601900Z",
     "start_time": "2025-04-21T11:18:46.958683100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_perspective(image):\n",
    "    rows, cols = image.shape[:2]\n",
    "    pts1 = np.float32([[0, 0], [cols-1, 0], [cols-1, rows-1], [0, rows-1]])\n",
    "    pts2 = np.float32([\n",
    "        [random.uniform(0, cols*0.2), random.uniform(0, rows*0.2)],\n",
    "        [random.uniform(cols*0.8, cols), random.uniform(0, rows*0.2)],\n",
    "        [random.uniform(cols*0.8, cols), random.uniform(rows*0.8, rows)],\n",
    "        [random.uniform(0, cols*0.2), random.uniform(rows*0.8, rows)]\n",
    "    ])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    return cv2.warpPerspective(image, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:46.997609600Z",
     "start_time": "2025-04-21T11:18:46.983187Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_background(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_bound = np.array([25, 40, 40])\n",
    "    upper_bound = np.array([90, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges_dilated = cv2.dilate(mask, kernel, iterations=2)\n",
    "\n",
    "    refined_mask = cv2.bitwise_or(mask, edges_dilated)\n",
    "\n",
    "    result = cv2.bitwise_and(image, image, mask=refined_mask)\n",
    "    alpha = refined_mask\n",
    "\n",
    "    b, g, r = cv2.split(result)\n",
    "    result = cv2.merge((b, g, r, alpha))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:18:47.007967100Z",
     "start_time": "2025-04-21T11:18:46.999358800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlay_image(background, overlay, position, scale=1.0, angle=0):\n",
    "    overlay = rembg_remove(overlay)\n",
    "\n",
    "    overlay = random_affine(overlay)\n",
    "    overlay = random_perspective(overlay)\n",
    "\n",
    "    h, w = overlay.shape[:2]\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    overlay_resized = cv2.resize(overlay, (new_w, new_h))\n",
    "\n",
    "    center = (new_w // 2, new_h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    overlay_resized = cv2.warpAffine(overlay_resized, M, (new_w, new_h))\n",
    "\n",
    "    x, y = position\n",
    "    h_bg, w_bg = background.shape[:2]\n",
    "\n",
    "    if x + new_w > w_bg or y + new_h > h_bg:\n",
    "        print(f\"Overlay exceeds background dimensions. {x + new_w} > {w_bg} or {y + new_h} > {h_bg}\")\n",
    "        return background\n",
    "\n",
    "    if overlay_resized.shape[2] == 4:\n",
    "        alpha = overlay_resized[:, :, 3] / 255.0\n",
    "        overlay_resized = overlay_resized[:, :, :3]\n",
    "    else:\n",
    "        alpha = np.ones((new_h, new_w))\n",
    "\n",
    "    for c in range(3):\n",
    "        background[y:y+new_h, x:x+new_w, c] = (\n",
    "            background[y:y+new_h, x:x+new_w, c] * (1 - alpha) +\n",
    "            overlay_resized[:, :, c] * alpha\n",
    "        )\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_paths = glob(f\"{BG_DIR}/*.jpg\") + glob(f\"{BG_DIR}/*.png\") + glob(f\"{BG_DIR}/*.JPG\")\n",
    "\n",
    "os.makedirs(OUT_BASE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:42:40.639549600Z",
     "start_time": "2025-04-21T11:36:25.108368500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for split in [\"train\", \"test\"]:\n",
    "    split_dir = os.path.join(LEAF_BASE, split)\n",
    "    print(\"SPLIT DIR\", split_dir)\n",
    "    for class_dir in os.listdir(split_dir):\n",
    "        class_path = os.path.join(split_dir, class_dir)\n",
    "        print(\"CLASS PATH\", class_path)\n",
    "        leaf_paths = glob(f\"{class_path}/*.png\") + glob(f\"{class_path}/*.JPG\")\n",
    "        print(len(leaf_paths))\n",
    "        output_class_dir = os.path.join(OUT_BASE, split, class_dir)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Processing {len(leaf_paths)} images from {split}/{class_dir}\")\n",
    "\n",
    "        for leaf_idx, leaf_path in enumerate(tqdm(leaf_paths, desc=f\"{split}/{class_dir}\")):\n",
    "            leaf = cv2.imread(leaf_path, cv2.IMREAD_UNCHANGED)\n",
    "            if leaf is None:\n",
    "                continue\n",
    "\n",
    "            for i in range(AUG_PER_LEAF):\n",
    "                bg_path = random.choice(bg_paths)\n",
    "                bg = cv2.imread(bg_path, cv2.IMREAD_UNCHANGED)\n",
    "                if bg is None:\n",
    "                    continue\n",
    "\n",
    "                bg = resize_with_aspect_ratio(bg, TARGET_WIDTH)\n",
    "\n",
    "                scale = random.uniform(1.5, 2.25)\n",
    "                new_w = int(leaf.shape[1] * scale)\n",
    "                new_h = int(leaf.shape[0] * scale)\n",
    "\n",
    "                max_x = max(0, bg.shape[1] - new_w)\n",
    "                max_y = max(0, bg.shape[0] - new_h)\n",
    "                x = random.randint(0, max_x)\n",
    "                y = random.randint(0, max_y)\n",
    "                angle = random.randint(0, 360)\n",
    "\n",
    "                composed = overlay_image(bg, leaf, (x, y), scale=scale, angle=angle)\n",
    "\n",
    "                leaf_name = Path(leaf_path).stem\n",
    "                out_path = os.path.join(output_class_dir, f\"{leaf_name}_aug{i+1}.png\")\n",
    "                cv2.imwrite(out_path, composed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
